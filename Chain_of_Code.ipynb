{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nnall6G_S_H"
      },
      "source": [
        "Copyright 2023 Google LLC. SPDX-License-Identifier: Apache-2.0\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC8NK7QSt7DJ"
      },
      "source": [
        "# Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x_emgqK0d7P"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.28\n",
        "!pip install tiktoken\n",
        "!pip install tqdm\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1eJJ9HU5rSV"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIRBhmE55lDN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import openai\n",
        "import tiktoken\n",
        "from tqdm.auto import trange, tqdm\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from types import NoneType\n",
        "import multiprocessing.dummy\n",
        "from io import StringIO\n",
        "from contextlib import redirect_stdout\n",
        "import signal\n",
        "from contextlib import contextmanager\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import ast\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amX1hDXoEfxI"
      },
      "source": [
        "# Set up API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWwegfs4Emb6"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"your_openai_api_key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY73QDgTUKiN"
      },
      "source": [
        "# Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F_Kl5jyUItW"
      },
      "outputs": [],
      "source": [
        "ENGINE = 'gpt-3.5-turbo'\n",
        "ANSWER_TOKEN = 'Answer: '\n",
        "CODE_START_TOKEN = \"# CODE START\"\n",
        "CODE_END_TOKEN = \"# CODE END\"\n",
        "MAX_TOKENS = 4096\n",
        "ENCODER = tiktoken.encoding_for_model(ENGINE)\n",
        "\n",
        "TOTAL_CORRECT_ANSWERS = 0\n",
        "FAILED_RUNS = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERhPDLg_T1Ll"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vreUkUlPoh3N"
      },
      "outputs": [],
      "source": [
        "def query_llm(prompt, max_tokens, stop=None, temperature=0):\n",
        "    \"\"\"\n",
        "    Give the prompt to the LLM and get response\n",
        "    \"\"\"\n",
        "    assert type(prompt)\n",
        "\n",
        "    if 'instruct' in ENGINE:\n",
        "        response = openai.Completion.create(prompt=prompt, model=ENGINE, max_tokens=max_tokens, temperature=temperature, stop=stop)\n",
        "        response_text = response.choices[0][\"text\"].strip()\n",
        "        return response_text\n",
        "    else:\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "        response = openai.ChatCompletion.create(messages=messages, model=ENGINE, max_tokens=max_tokens, temperature=temperature, stop=stop)\n",
        "        return response['choices'][0]['message']['content'].strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqgzkRu7YEi4"
      },
      "outputs": [],
      "source": [
        "def print_result(method, response, answer, correct_answer):\n",
        "  global TOTAL_CORRECT_ANSWERS\n",
        "\n",
        "  with open('output.txt', 'a') as f:\n",
        "    print(\"#### Full Response ####\", file=f)\n",
        "    print(response, file=f)\n",
        "    print(\"#### Model Answer ####\", file=f)\n",
        "    print(answer, file=f)\n",
        "    print(\"#### Correct Answer ####\", file=f)\n",
        "    print(correct_answer, file=f)\n",
        "\n",
        "  if str(answer).strip().lower() == str(correct_answer).strip().lower():\n",
        "    TOTAL_CORRECT_ANSWERS += 1\n",
        "\n",
        "  # print(\"#### Method ####\")\n",
        "  # print(method)\n",
        "  # print(\"#### Full Response ####\")\n",
        "  # print(response)\n",
        "  # print(\"#### Model Answer ####\")\n",
        "  # print(answer)\n",
        "  # print(\"#### Correct Answer ####\")\n",
        "  # print(correct_answer)\n",
        "  # if str(answer).strip().lower() == str(correct_answer).strip().lower():\n",
        "  #   TOTAL_CORRECT_ANSWERS += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_generation_prompt = \"\"\"Q: Which sentence has the correct adjective order:\n",
        "Options:\n",
        "(A) rubber terrible ship\n",
        "(B) terrible rubber ship\n",
        "A:\n",
        "# CODE START\n",
        "import numpy as np\n",
        "options = {\"(A)\": \"rubber terrible ship\", \"(B)\": \"terrible rubber ship\"}\n",
        "priority = {\"opinion\": 1, \"size\": 2, \"age\": 3, \"shape\": 4, \"color\": 5, \"origin\": 6, \"material\": 7, \"purpose\": 8}\n",
        "valid_types = list(priority.keys())\n",
        "scores = []\n",
        "for option, sentence in options.items():\n",
        "  adjectives = sentence.split(\" \")[:-1]\n",
        "  order = [priority[get_adjective_type(adjective, valid_types, ret_type=str)] for adjective in adjectives]\n",
        "  scores.append([order[i+1] > order[i] for i in range(len(order) - 1)].count(True))\n",
        "answer = list(options.keys())[np.argmax(scores)]\n",
        "# CODE END\n",
        "\n",
        "Q: Today is Christmas Eve of 1937. What is the date 10 days ago in MM/DD/YYYY?\n",
        "A:\n",
        "# CODE START\n",
        "import datetime\n",
        "options = {\"12/14/2026\": \"(A)\", \"12/14/1950\": \"(B)\", \"12/14/2007\": \"(C)\", \"12/14/1937\": \"(D)\", \"07/14/1938\": \"(E)\", \"12/14/1988\": \"(F)\"}\n",
        "today = datetime.date(year=1937, month=12, day=24)\n",
        "date = today - datetime.timedelta(days=10)\n",
        "answer = date.strftime(\"%m/%d/%Y\")\n",
        "# CODE END\n",
        "\n",
        "Q: Recommend a movie similar to Star Wars Episode IV - A New Hope, Indiana Jones and the Last Crusade, Star Wars Episode V - The Empire Strikes Back, The Big Lebowski:\n",
        "A:\n",
        "# CODE START\n",
        "ref_movies = [\"Star Wars Episode IV - A New Hope\", \"Indiana Jones and the Last Crusade\", \"Star Wars Episode V - The Empire Strikes Back\", \"The Big Lebowski\"]\n",
        "ref_movie_infos = get_movie_genre_and_year(ref_movies, ret_type=\"list[tuple[str, int]]\")\n",
        "answer = get_most_similar_movie(ref_movies, ref_movie_infos, ret_type=\"str\")\n",
        "# CODE END\n",
        "\n",
        "Q: bhgvynv is a hamster, sppqg is an ant, so bhgvynv is more likely to spin on a wheel than sppqg. True or False?\n",
        "A:\n",
        "# CODE START\n",
        "entities = {\"bhgvynv\": \"hamster\", \"sppqg\": \"ant\"}\n",
        "answer = is_more_likely_to_spin_on_a_wheel(entities[\"bhgvynv\"], entities[\"sppqg\"])\n",
        "# CODE END\n",
        "\n",
        "Q: kabazpvx is a bee, ixex is a dolphin, so kabazpvx is not less likely to be in a meadow than ixex. True or False?\n",
        "A:\n",
        "# CODE START\n",
        "entities = {\"kabazpvx\": \"bee\", \"ixex\": \"dolphin\"}\n",
        "answer = is_not_less_likely_to_be_in_a_meadow(entities[\"kabazpvx\"], entities[\"inex\"])\n",
        "# CODE END\n",
        "\n",
        "Q: pcmzhdkoqcs walks around town while qjopibkxim does not, so qjopibkxim is not a less explorer than pcmzhdkoqcs. True or False?\n",
        "A:\n",
        "# CODE START\n",
        "entities = {\"pcmzhdkoqcs\": \"walks around town\", \"qjopibkxim\": \"does not walk about town\"}\n",
        "answer = is_not_a_less_explorer(entities[\"qjopibkxim\"], entities[\"pcmzhdkoqcs\"])\n",
        "# CODE END\n",
        "\n",
        "Q: trej waits for jrxwtuuau's return while jrxwtuuau does not, so trej is not less patient than jrxwtuuau. True or False?\n",
        "A:\n",
        "# CODE START\n",
        "entities = {\"trej\": \"waits for return\", \"jrxwtuuau\": \"does not wait for return\"}\n",
        "answer = is_not_less_patient(entities[\"trej\"], entities[\"jrxwtuuau\"])\n",
        "# CODE END\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ohVWwhl9coCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lmulator_prompt = \"\"\"# TRACE START\n",
        "state: {}\n",
        "line: adjective = \"red\"\n",
        "delta state: {'adjective': 'red'}\n",
        "line: valid_types = {\"opinion\", \"size\", \"age\", \"shape\", \"color\", \"origin\", \"material\", \"purpose\"}\n",
        "delta state: {'valid_types': {'opinion', 'size', 'age', 'shape', 'color', 'origin', 'material', 'purpose'}}\n",
        "line: adj_type = get_adjective_type(adjective, valid_types, ret_type=str)\n",
        "delta state: {'adj_type': 'color'}\n",
        "# TRACE END\n",
        "\n",
        "# TRACE START\n",
        "state: {}\n",
        "line: obj1 = \"soda can\"\n",
        "delta state: {'obj1': 'soda can'}\n",
        "line: is_obj1_recyclable = is_recyclable(obj1, ret_type=bool)\n",
        "delta state: {'is_obj1_recyclable': True}\n",
        "line: obj2 = \"fruit\"\n",
        "delta state: {'obj2': 'fruit'}\n",
        "line: is_obj2_recyclable = is_recyclable(obj2, ret_type=bool)\n",
        "delta state: {'is_obj2_recyclable': False}\n",
        "# TRACE END\n",
        "\n",
        "# TRACE START\n",
        "state: {}\n",
        "line: num1 = 23\n",
        "delta state: {'num1': 23}\n",
        "line: num2 = 52\n",
        "delta state: {'num2': 52}\n",
        "line: sum_of_two = num1 + num2\n",
        "delta state: {'sum_of_two': 75}\n",
        "line: greated_than_one_hundred = is_greater(sum_of_two, 100)\n",
        "delta state: {'greated_than_one_hundred': False}\n",
        "# TRACE END\n",
        "\n",
        "# TRACE START\n",
        "state: {}\n",
        "line: entities = {\"bhgvynv\": \"hamster\", \"sppqg\": \"ant\"}\n",
        "delta state: {'entities': {'bhgvynv': 'hamster', 'sppqg': 'ant'}}\n",
        "line: answer = is_not_less_likely_to_be_in_a_meadow(entities[\"kabazpvx\"], entities[\"inex\"])\n",
        "delta state: {'answer': True}\n",
        "# TRACE END\n",
        "\n",
        "# TRACE START\n",
        "state: {}\"\"\""
      ],
      "metadata": {
        "id": "aRJ3VJk9coCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors = {}\n",
        "error_lineno = None\n",
        "lines = None\n",
        "trace_lines = []\n",
        "last_state = None\n",
        "\n",
        "def get_delta_state(state, last_state):\n",
        "  \"\"\"\n",
        "  This method indicates the difference between the current state and the\n",
        "  last state. So it focses on the differences between two consecutive states.\n",
        "\n",
        "  Returns a dictionary that contains info about the changes between two states.\n",
        "  \"\"\"\n",
        "  delta_state = {}\n",
        "  for key, val in state.items():\n",
        "    if key not in last_state or val != last_state[key]:\n",
        "      delta_state[key] = val\n",
        "  return delta_state\n",
        "\n",
        "def get_state(frame):\n",
        "  \"\"\"\n",
        "  This method 'captures' and returns the local variables that currently in\n",
        "  the frame that we pass as an argument\n",
        "  \"\"\"\n",
        "  state = {}\n",
        "  for key, item in frame.f_locals.items():\n",
        "    if isinstance(item, (bool, str, int, float, tuple, list, set, dict, NoneType)):\n",
        "      state[key] = item\n",
        "  return state\n",
        "\n",
        "def show_trace(frame, event, arg):\n",
        "  # Declare these global variable first\n",
        "  global errors\n",
        "  global error_lineno\n",
        "  global lines\n",
        "  global trace_lines\n",
        "  global last_state\n",
        "  global lines_run_history\n",
        "\n",
        "  # The LLM-generated code will be wrapped around in the get_answer function call.\n",
        "  # If we don't filter by \"get_answer\", we got a bunch of random exception from colab\n",
        "  if frame.f_code.co_name != \"get_answer\":\n",
        "    return\n",
        "\n",
        "  lineno = frame.f_lineno - 1\n",
        "  # Running a certain line\n",
        "  if event == \"line\":\n",
        "    current_line = lines[lineno]\n",
        "    if current_line.strip() in [\"try:\", \"except:\", \"pass\"]:\n",
        "      pass\n",
        "    elif current_line.strip() == \"return answer\":\n",
        "      assert lineno == len(lines) - 2, \"return answer is at the wrong line\" # Second to last line\n",
        "      state = get_state(frame)\n",
        "      assert last_state is not None\n",
        "      delta_state = get_delta_state(state, last_state)\n",
        "      trace_lines.append(f\"delta state: {delta_state}\")\n",
        "      # Append the final state\n",
        "      trace_lines.append(f\"final state: {state}\")\n",
        "    elif lineno not in errors:\n",
        "      # We previous indent 2 spaces\n",
        "      assert current_line[:2] == \"  \", f\"Python: actual line to run doesn't have two leading spaces: {current_line} {lines}\"\n",
        "      # Now we revert back\n",
        "      current_line = current_line[2:]\n",
        "\n",
        "      state = get_state(frame)\n",
        "\n",
        "      delta_state = None\n",
        "      if last_state is None:\n",
        "        delta_state = None\n",
        "      else:\n",
        "        delta_state = get_delta_state(state, last_state)\n",
        "      last_state = copy.deepcopy(state)\n",
        "\n",
        "      if delta_state is None:\n",
        "        trace_lines.append(\"state: {}\")\n",
        "      else:\n",
        "        trace_lines.append(f\"delta state: {delta_state}\")\n",
        "      trace_lines.append(f\"line: {current_line}\")\n",
        "\n",
        "    else:\n",
        "\n",
        "      # We previous indent 4 spaces\n",
        "      assert current_line[:4] == \"    \", f\"LLM: actual line to run doesn't have four leading spaces: {current_line} {lines}\"\n",
        "      # Now we revert back\n",
        "      current_line = current_line[4:]\n",
        "      # When LLM excutes, remove any trailing space at the beginning\n",
        "\n",
        "      state = get_state(frame)\n",
        "      delta_state = None\n",
        "      if last_state is None:\n",
        "        delta_state = None\n",
        "      else:\n",
        "        delta_state = get_delta_state(state, last_state)\n",
        "      last_state = copy.deepcopy(state)\n",
        "\n",
        "      if delta_state is None:\n",
        "        trace_lines.append(\"state: {}\")\n",
        "      else:\n",
        "        trace_lines.append(f\"delta state: {delta_state}\")\n",
        "      trace_lines.append(f\"line: {current_line}\")\n",
        "\n",
        "      # Due to the context length constraint, only feed in the last three lines of the trace.\n",
        "      prompt = lmulator_prompt + \"\\n\" + \"\\n\".join(trace_lines[-3:]) + \"\\n\" + \"delta state:\"\n",
        "\n",
        "      token_length = len(ENCODER.encode(prompt))\n",
        "\n",
        "      llm_result = query_llm(prompt, max_tokens=32, stop=[\"\\nline:\"])\n",
        "\n",
        "      program_state_str = llm_result.strip()\n",
        "      try:\n",
        "        new_program_state = ast.literal_eval(program_state_str)\n",
        "        assert isinstance(new_program_state, dict), \"new program state is not a valid dict\"\n",
        "        # Actually update the local variables with the new program state\n",
        "        frame.f_locals.update(new_program_state)\n",
        "      except Exception as e:\n",
        "        raise e\n",
        "\n",
        "  elif event == \"exception\":\n",
        "    # Only capture the lowest level exception AND if this exception hasn't been \"fixed\" before, i.e. this line hasn't be sandwiched by try/except yet.\n",
        "    if error_lineno is None and lineno not in errors:\n",
        "      error_lineno = lineno\n",
        "\n",
        "  return show_trace\n",
        "\n",
        "sys.settrace(show_trace)"
      ],
      "metadata": {
        "id": "XNV9AsRecoCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlhD1QGtcoCb"
      },
      "outputs": [],
      "source": [
        "def evaluate_coc(prompt, query, correct_answer):\n",
        "  \"\"\"\n",
        "  Evaluates the response from the CoC approach.\n",
        "\n",
        "  Queries LLM\n",
        "  Parses Response to extract Generated Code (between 'CODE_START_TOKEN' and 'CODE_END_TOKEN')\n",
        "  Creates the 'code_to_run' obj that contains the code\n",
        "  'max_trials': times that the loop can run\n",
        "  \"\"\"\n",
        "\n",
        "  global errors\n",
        "  global error_lineno\n",
        "  global lines\n",
        "  global trace_lines\n",
        "  global last_state\n",
        "  global FAILED_RUNS\n",
        "\n",
        "  coc_response = query_llm(prompt + \"\\n\\n\" + query, max_tokens=1024)\n",
        "\n",
        "  if CODE_START_TOKEN not in coc_response or CODE_END_TOKEN not in coc_response:\n",
        "    FAILED_RUNS += 1\n",
        "    return\n",
        "  code_to_run = coc_response.split(CODE_START_TOKEN)[1].split(CODE_END_TOKEN)[0].strip()\n",
        "\n",
        "  answer = None\n",
        "  max_trials = 10\n",
        "  # Wrap the code inside the get_answer function call\n",
        "  code_to_run_temp = code_to_run.split(\"\\n\")\n",
        "  code_to_run = \"\\n\".join([\"  \" + l for l in code_to_run_temp])\n",
        "  code_to_run = f\"\"\"def get_answer():\n",
        "{code_to_run}\n",
        "  return answer\n",
        "answer = get_answer()\"\"\"\n",
        "\n",
        "\n",
        "  lines = code_to_run.split(\"\\n\")\n",
        "  local_vars = locals()\n",
        "\n",
        "  for num_trial in range(max_trials):\n",
        "    with open('output.txt', 'a') as f:\n",
        "      print(f\"Trial is {num_trial+1}\", file=f)\n",
        "\n",
        "    if sys.gettrace() is None: sys.settrace(show_trace)\n",
        "    assert sys.gettrace() is not None, \"get trace is None\"\n",
        "    try:\n",
        "      # answer will be populated by exec function.\n",
        "      exec(code_to_run, globals(), local_vars)\n",
        "      coc_answer = local_vars[\"answer\"]\n",
        "      assert coc_answer is not None\n",
        "      break\n",
        "    except Exception as e:\n",
        "      assert error_lineno is not None\n",
        "      # Update errors\n",
        "      line = lines[error_lineno]\n",
        "      errors[error_lineno + 1] = line\n",
        "\n",
        "      # Update lines and code_to_run\n",
        "      num_indent = len(line) - len(line.lstrip())\n",
        "      lines[error_lineno] = \" \" * 2 + lines[error_lineno]\n",
        "      lines.insert(error_lineno, \" \" * num_indent + \"try:\")\n",
        "      lines.insert(error_lineno + 2, \" \" * num_indent + \"except:\")\n",
        "      lines.insert(error_lineno + 3, \" \" * (num_indent + 2) + \"pass\")\n",
        "      code_to_run = \"\\n\".join(lines)\n",
        "\n",
        "      # Reset error_lineno and trace_lines\n",
        "      error_lineno = None\n",
        "      trace_lines = []\n",
        "      last_state = None\n",
        "\n",
        "  print_result('CoC', coc_response, coc_answer, correct_answer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"RICA_for_CoC.json\", 'r') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "\n",
        "  TOTAL_CORRECT_ANSWERS = 0\n",
        "  FAILED_RUNS = 0\n",
        "\n",
        "  for index, item in enumerate(data):\n",
        "    sys.settrace(show_trace)\n",
        "\n",
        "    with open('output.txt', 'a') as f:\n",
        "      print(f\"RICA Statement no.{index}\", file=f)\n",
        "\n",
        "    print(f\"RICA Statement no.{index}\")\n",
        "\n",
        "    query = f\"\"\"\n",
        "    Q: {item['question']}\n",
        "    \"\"\".strip()\n",
        "\n",
        "    try:\n",
        "      evaluate_coc(code_generation_prompt, query, item['answer'])\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      FAILED_RUNS += 1\n",
        "\n",
        "    with open('output.txt', 'a') as f:\n",
        "      print(\"\\n\", file=f)\n",
        "\n",
        "with open('output.txt', 'a') as f:\n",
        "  print(f\"Total correct answers: {TOTAL_CORRECT_ANSWERS}\", file=f)\n",
        "  print(f\"Total failed runs: {FAILED_RUNS}\", file=f)\n",
        "\n",
        "\n",
        "print(f\"Total correct answers: {TOTAL_CORRECT_ANSWERS}\")\n",
        "print(f\"Total failed runs: {FAILED_RUNS}\")"
      ],
      "metadata": {
        "id": "EihKyshJcoCc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}